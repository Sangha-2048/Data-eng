PGAdmin: web based GUI tool to interact with postgres db session

# Using docker image 
docker run -it -e PGADMIN_DEFAULT_EMAIL="admin@admin.com" -e PGADMIN_DEFAULT_PASSWORD="root" -p 8080:80 dpage/pgadmin4

# Application running on:
http://localhost:8080/login?next=%2F

# In PGAdmin create a server
PGAdmin is running on one container and Postgres is running on another container, to form a link, we'll put
them in a single network

# Using docker network
-> docker network create pg-network
 
	# Modifying docker commands to include them into a network
	docker run -it -e PGADMIN_DEFAULT_EMAIL="admin@admin.com" -e PGADMIN_DEFAULT_PASSWORD="root" -p 8080:80 --network=pg-network --name pgadmin dpage/pgadmin4

	docker run -it -e POSTGRES_USER="root" -e POSTGRES_PASSWORD="root" -e POSTGRES_DB="ny_taxi_postgres_data" -v $(pwd)/ny_taxi_postgres_data:/var/lib/postgres/data -p 5432:5432 --network=pg-network --name pg-database2 postgres:13

# Using lib called argparse to read command line args
	parser = argparse.ArgumentParser(description='Ingest CSV data to postgres')

	parser.add_argument('--user', help='user name for postgres')
	parser.add_argument('--pwd', help='password for postgres')
	args = parser.parse_args()
	print(args.accumulate(args.integers))

	main(args)

# List all the docker networks
docker network list

# Diff b/w docker image and docker container
The key difference between a Docker image Vs a container is that a Docker image 
is a read-only immutable template that defines how a container will be 
realized. A Docker container is a runtime instance of a Docker image that 
gets created when the $ docker run command is implemented

# To list all running containers
docker container ls

# In case of permission denied error
sudo chmod 666 /var/run/docker.sock

# To start services
docker-compose up
# Needs docker-compose.yml

# To start postgres and PGAdmin service in one network use docker-compose up command
# Avoid using tabs in docker-compose.yml file

# To delete a branch from remote 
git push origin -d <branch_name>
git push origin -d py-2

++++++++++++++++++++++++++++++++++++++++++++++++
Terraform and GCP (Google Cloud Plateform) notes
++++++++++++++++++++++++++++++++++++++++++++++++

Terraform is an infrastructure as code tool that allows us to provision infrastructure resources as code, 
thus making it possible to handle infrastructure as an additional software component and take advantage of 
tools such as version control. It also allows us to bypass the cloud vendor GUIs.

During this course we will use Google Cloud Platform (GCP) as our cloud services provider.

What is Terraform?
1. open-source tool by HashiCorp, used for provisioning infrastructure resources ( can be VMs, containers, 
networking resources).
2. supports DevOps best practices for change management
3. Managing configuration files in source control to maintain an ideal provisioning 
state for testing and production environments
4. use IaC style approach

What is IaC?
1. Infrastructure-as-Code
build, change, and manage your infrastructure in a safe, consistent, and repeatable way by defining resource 
configurations that you can version, reuse, and share.

Some advantages
1. Infrastructure lifecycle management
2. Version control commits
3. Very useful for stack-based deployments, and with cloud providers such as AWS, GCP, Azure, K8Sâ€¦
4. State-based approach to track resource changes throughout deployments

=> Files and Declarations

Files
1. main.tf
2 .variables.tf
3. Optional: resources.tf, output.tf
	.tfstate

Declarations
1. terraform: configure basic Terraform settings to provision your infrastructure

2. required_version: minimum Terraform version to apply to your configuration

3. backend: stores Terraform's "state" snapshots, to map real-world resources to your configuration.

4. local: stores state file locally as terraform.tfstate

5. required_providers: specifies the providers required by the current module

6. provider:
-> adds a set of resource types and/or data sources that Terraform can manage
-> The Terraform Registry is the main directory of publicly available providers from most major infrastructure platforms.

7. resource:
-> blocks to define components of your infrastructure
-> Project modules/resources: google_storage_bucket, google_bigquery_dataset, google_bigquery_table
8. variable & locals:
-> runtime arguments and constants

Execution steps

1. terraform init:
-> Initializes & configures the backend, installs plugins/providers, & checks out an existing configuration from a version control

2. terraform plan:
-> Matches/previews local changes against a remote state, and proposes an Execution Plan.

3. terraform apply:
->Asks for approval to the proposed plan, and applies changes to cloud

4. terraform destroy
-> Removes your stack from the Cloud
